{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import print_function\n",
    "import torch as t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1513, -0.7035,  0.4673, -0.0636],\n",
       "        [ 0.6161,  2.1867, -0.3138,  1.1641],\n",
       "        [ 0.2883,  1.4634, -0.0858,  0.1266]], requires_grad=True)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#在创建tensor的时候指定requires_grad\n",
    "a = t.randn(3, 4, requires_grad=True)\n",
    "#或者\n",
    "a = t.randn(3, 4).requires_grad_()\n",
    "#或者\n",
    "a = t.randn(3, 4)\n",
    "a.requires_grad = True\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]], requires_grad=True)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = t.zeros(3, 4).requires_grad_()\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.1513, -0.7035,  0.4673, -0.0636],\n",
       "        [ 0.6161,  2.1867, -0.3138,  1.1641],\n",
       "        [ 0.2883,  1.4634, -0.0858,  0.1266]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = a.add(b)\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5.2970, grad_fn=<SumBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = c.sum()\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "d.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d\n",
    "d.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 此处虽然没有指定c需要求导，但c依赖于a，而a需要求导，\n",
    "# 因此c的requires_grad属性会自动设为True\n",
    "a.requires_grad, b.requires_grad, c.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 由用户创建的variable属于叶子节点，对应的grad_fn是None\n",
    "a.is_leaf, b.is_leaf, c.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# c.grad是None, 因c不是叶子节点，它的梯度是用来计算a的梯度\n",
    "# 所以虽然c.requires_grad = True,但其梯度计算完之后即被释放\n",
    "c.grad is None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "计算下面这个函数的导函数： $$ y = x^2\\bullet e^x $$ 它的导函数是： $$ {dy \\over dx} = 2x\\bullet e^x + x^2 \\bullet e^x $$ 来看看autograd的计算结果与手动求导计算结果的误差。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def f(x):\n",
    "    #计算y\n",
    "    y = x**2 * t.exp(x)\n",
    "    return y\n",
    "\n",
    "\n",
    "def gradf(x):\n",
    "    '''手动求导函数'''\n",
    "    dx = 2 * x * t.exp(x) + x**2 * t.exp(x)\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[8.5839e-02, 5.6158e-02, 5.6780e+00, 2.1906e-01],\n",
       "        [5.6226e-03, 6.1096e+00, 1.9775e+01, 6.2682e-02],\n",
       "        [7.8505e-03, 9.3031e-01, 5.3128e-01, 2.8707e+00]],\n",
       "       grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.randn(3, 4, requires_grad=True)\n",
    "y = f(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4063,  0.5834, 14.6511, -0.4584],\n",
       "        [-0.1386, 15.5515, 41.6955,  0.6227],\n",
       "        [-0.1613,  3.6471, -0.0799,  8.5089]])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.backward(t.ones(y.size()))\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.4063,  0.5834, 14.6511, -0.4584],\n",
       "        [-0.1386, 15.5515, 41.6955,  0.6227],\n",
       "        [-0.1613,  3.6471, -0.0799,  8.5089]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# autograd的计算结果与利用公式手动计算的结果一致\n",
    "gradf(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(1)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "b = t.rand(1, requires_grad=True)\n",
    "w = t.rand(1, requires_grad=True)\n",
    "y = w * x\n",
    "z = y + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, True)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.requires_grad, b.requires_grad, w.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 虽然未指定y.requires_grad为True，但由于y依赖于需要求导的w\n",
    "# 故而y.requires_grad为True\n",
    "y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x.is_leaf, w.is_leaf, b.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.is_leaf, z.is_leaf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AddBackward0 at 0x7f2aba5ad278>"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# grad_fn可以查看这个variable的反向传播函数，\n",
    "# z是add函数的输出，所以它的反向传播函数是AddBackward\n",
    "z.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<MulBackward0 at 0x7f2aba5b2080>, 0),\n",
       " (<AccumulateGrad at 0x7f2aba5b20f0>, 0))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# next_functions保存grad_fn的输入，是一个tuple，tuple的元素也是Function\n",
    "# 第一个是y，它是乘法(mul)的输出，所以对应的反向传播函数y.grad_fn是MulBackward\n",
    "# 第二个是b，它是叶子节点，由用户创建，grad_fn为None，但是有\n",
    "z.grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# variable的grad_fn对应着和图中的function相对应\n",
    "z.grad_fn.next_functions[0][0] == y.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "z.grad_fn.next_functions[1][0] == b.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "b.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((<AccumulateGrad at 0x7f2aba5ab1d0>, 0), (None, 0))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.grad_fn.next_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, None, None)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w.grad_fn, x.grad_fn, b.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 使用retain_graph来保存buffer\n",
    "z.backward(retain_graph=True)\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2.])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 多次反向传播，梯度累加，这也就是w中AccumulateGrad标识的含义\n",
    "z.backward()\n",
    "w.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "PyTorch使用的是动态图，它的计算图在每次前向传播时都是从头开始构建，所以它能够使用Python控制语句（如for、if等）根据需求创建计算图。这点在自然语言处理领域中很有用，它意味着你不需要事先构建所有可能用到的图的路径，图在运行时才构建。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def abs(x):\n",
    "    if x.data[0] > 0: return x\n",
    "    else: return -x\n",
    "\n",
    "\n",
    "x = t.ones(1, requires_grad=True)\n",
    "y = abs(x)\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-1.])\n"
     ]
    }
   ],
   "source": [
    "x = -1 * t.ones(1)\n",
    "x = x.requires_grad_()\n",
    "y = abs(x)\n",
    "y.backward()\n",
    "print(x.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0., 0., 0., 6., 3., 2.])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def f(x):\n",
    "    result = 1\n",
    "    for ii in x:\n",
    "        if ii.item() > 0: result = ii * result\n",
    "    return result\n",
    "\n",
    "\n",
    "x = t.arange(-2., 4, requires_grad=True)\n",
    "y = f(x)  # y = x[3]*x[4]*x[5]\n",
    "y.backward()\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "变量的requires_grad属性默认为False，如果某一个节点requires_grad被设置为True，那么所有依赖它的节点requires_grad都是True。这其实很好理解，对于$ \\textbf{x}\\to \\textbf{y} \\to \\textbf{z}$，x.requires_grad = True，当需要计算$\\partial z \\over \\partial x$时，根据链式法则，$\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial y} \\frac{\\partial y}{\\partial x}$，自然也需要求$ \\frac{\\partial z}{\\partial y}$，所以y.requires_grad会被自动标为True.\n",
    "\n",
    "有些时候我们可能不希望autograd对tensor求导。认为求导需要缓存许多中间结构，增加额外的内存/显存开销，那么我们可以关闭自动求导。对于不需要反向传播的情景（如inference，即测试推理时），关闭自动求导可实现一定程度的速度提升，并节省约一半显存，因其不需要分配空间计算梯度。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(1, requires_grad=True)\n",
    "w = t.rand(1, requires_grad=True)\n",
    "y = x * w\n",
    "# y依赖于w，而w.requires_grad = True\n",
    "x.requires_grad, w.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, False)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with t.no_grad():\n",
    "    x = t.ones(1)\n",
    "    w = t.rand(1, requires_grad=True)\n",
    "    y = x * w\n",
    "# y依赖于w和x，虽然w.requires_grad = True，但是y的requires_grad依旧为False\n",
    "x.requires_grad, w.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.autograd.grad_mode.no_grad"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.no_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False, True, False)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.set_grad_enabled(False)\n",
    "x = t.ones(1)\n",
    "w = t.rand(1, requires_grad=True)\n",
    "y = x * w\n",
    "# y依赖于w和x，虽然w.requires_grad = True，但是y的requires_grad依旧为False\n",
    "x.requires_grad, w.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f2aba5af128>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 恢复默认配置\n",
    "t.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = t.ones(3, 4, requires_grad=True)\n",
    "b = t.ones(3, 4, requires_grad=True)\n",
    "c = a * b\n",
    "\n",
    "a.data  # 还是一个tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.data.requires_grad  # 但是已经是独立于计算图之外"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d = a.data.sigmoid_()  # sigmoid_ 是个inplace操作，会修改a自身的值\n",
    "d.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7311, 0.7311, 0.7311, 0.7311],\n",
       "        [0.7311, 0.7311, 0.7311, 0.7311],\n",
       "        [0.7311, 0.7311, 0.7311, 0.7311]], requires_grad=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如果我们希望对tensor，但是又不希望被记录, 可以使用tensor.data 或者tensor.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 近似于 tensor=a.data, 但是如果tensor被修改，backward可能会报错\n",
    "tensor = a.detach()\n",
    "tensor.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 统计tensor的一些指标，不希望被记录\n",
    "mean = tensor.mean()\n",
    "std = tensor.std()\n",
    "maximum = tensor.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor[0] = 1\n",
    "# 下面会报错：　RuntimeError: one of the variables needed for gradient\n",
    "#             computation has been modified by an inplace operation\n",
    "#　因为 c=a*b, b的梯度取决于a，现在修改了tensor，其实也就是修改了a，梯度不再准确\n",
    "# c.sum().backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "在反向传播过程中非叶子节点的导数计算完之后即被清空。若想查看这些变量的梯度，有两种方法：\n",
    "\n",
    "    使用autograd.grad函数\n",
    "    使用hook\n",
    "\n",
    "autograd.grad和hook方法都是很强大的工具，更详细的用法参考官方api文档，这里举例说明基础的使用。推荐使用hook方法，但是在实际使用中应尽量避免修改grad的值。\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, True)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(3, requires_grad=True)\n",
    "w = t.rand(3, requires_grad=True)\n",
    "y = x * w\n",
    "# y依赖于w，而w.requires_grad = True\n",
    "z = y.sum()\n",
    "x.requires_grad, w.requires_grad, y.requires_grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.2461, 0.6311, 0.1082]), tensor([1., 1., 1.]), None)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 非叶子节点grad计算完之后自动清空，y.grad是None\n",
    "z.backward()\n",
    "(x.grad, w.grad, y.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1., 1., 1.]),)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 第一种方法：使用grad获取中间变量的梯度\n",
    "x = t.ones(3, requires_grad=True)\n",
    "w = t.rand(3, requires_grad=True)\n",
    "y = x * w\n",
    "z = y.sum()\n",
    "# z对y的梯度，隐式调用backward()\n",
    "t.autograd.grad(z, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y的梯度： tensor([1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "# 第二种方法：使用hook\n",
    "# hook是一个函数，输入是梯度，不应该有返回值\n",
    "def variable_hook(grad):\n",
    "    print('y的梯度：', grad)\n",
    "\n",
    "\n",
    "x = t.ones(3, requires_grad=True)\n",
    "w = t.rand(3, requires_grad=True)\n",
    "y = x * w\n",
    "# 注册hook\n",
    "hook_handle = y.register_hook(variable_hook)\n",
    "z = y.sum()\n",
    "z.backward()\n",
    "\n",
    "# 除非你每次都要用hook，否则用完之后记得移除hook\n",
    "hook_handle.remove()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "最后再来看看variable中grad属性和backward函数grad_variables参数的含义，这里直接下结论：\n",
    "\n",
    "   *  variable $\\textbf{x}$的梯度是目标函数${f(x)} $对$\\textbf{x}$的梯度，$\\frac{df(x)}{dx} = (\\frac {df(x)}{dx_0},\\frac {df(x)}{dx_1},...,\\frac {df(x)}{dx_N})$，形状和$\\textbf{x}$一致。\n",
    "   *  对于y.backward(grad_variables)中的grad_variables相当于链式求导法则中的$\\frac{\\partial z}{\\partial x} = \\frac{\\partial z}{\\partial y} \\frac{\\partial y}{\\partial x}$中的$\\frac{\\partial z}{\\partial y}$。z是目标函数，一般是一个标量，故而$\\frac{\\partial z}{\\partial y}$的形状与variable $\\textbf{y}$的形状一致。z.backward()在一定程度上等价于y.backward(grad_y)。z.backward()省略了grad_variables参数，是因为$z$是一个标量，而$\\frac{\\partial z}{\\partial z} = 1$\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.arange(0., 3, requires_grad=True)\n",
    "y = x**2 + x * 2\n",
    "z = y.sum()\n",
    "z.backward()  # 从z开始反向传播\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 4., 6.])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.arange(0., 3, requires_grad=True)\n",
    "y = x**2 + x * 2\n",
    "z = y.sum()\n",
    "y_gradient = t.Tensor([1, 1, 1])  # dz/dy\n",
    "y.backward(y_gradient)  #从y开始反向传播\n",
    "x.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "另外值得注意的是，只有对variable的操作才能使用autograd，如果对variable的data直接进行操作，将无法使用反向传播。除了对参数初始化，一般我们不会修改variable.data的值。\n",
    "\n",
    "在PyTorch中计算图的特点可总结如下：\n",
    "\n",
    "   * autograd根据用户对variable的操作构建其计算图。对变量的操作抽象为Function。\n",
    "   * 对于那些不是任何函数(Function)的输出，由用户创建的节点称为叶子节点，叶子节点的grad_fn为None。叶子节点中需要求导的variable，具有AccumulateGrad标识，因其梯度是累加的。\n",
    "   * variable默认是不需要求导的，即requires_grad属性默认为False，如果某一个节点requires_grad被设置为True，那么所有依赖它的节点requires_grad都为True。\n",
    "   * variable的volatile属性默认为False，如果某一个variable的volatile属性被设为True，那么所有依赖它的节点volatile属性都为True。volatile属性为True的节点不会求导，volatile的优先级比requires_grad高。\n",
    "   * 多次反向传播时，梯度是累加的。反向传播的中间缓存会被清空，为进行多次反向传播需指定retain_graph=True来保存这些缓存。\n",
    "   * 非叶子节点的梯度计算完之后即被清空，可以使用autograd.grad或hook技术获取非叶子节点的值。\n",
    "   * variable的grad与data形状一致，应避免直接修改variable.data，因为对data的直接操作无法利用autograd进行反向传播\n",
    "   * 反向传播函数backward的参数grad_variables可以看成链式求导的中间结果，如果是标量，可以省略，默认为1\n",
    "   * PyTorch采用动态图设计，可以很方便地查看中间层的输出，动态的设计计算图结构。\n",
    "\n",
    "这些知识不懂大多数情况下也不会影响对pytorch的使用，但是掌握这些知识有助于更好的理解pytorch，并有效的避开很多陷阱\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 扩展autograd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "目前绝大多数函数都可以使用autograd实现反向求导，但如果需要自己写一个复杂的函数，不支持自动反向求导怎么办? 写一个Function，实现它的前向传播和反向传播代码，Function对应于计算图中的矩形， 它接收参数，计算并返回结果。下面给出一个例子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Function' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-69-1ba462cf0e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mMul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mFunction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mstaticmethod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mctx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_requires_grad\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_requires_grad\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx_requires_grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m         \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_for_backward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mw\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'Function' is not defined"
     ]
    }
   ],
   "source": [
    "class Mul(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, w, x, b, x_requires_grad=True):\n",
    "        ctx.x_requires_grad = x_requires_grad\n",
    "        ctx.save_for_backward(w, x)\n",
    "        output = w * x + b\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        w, x = ctx.saved_tensors\n",
    "        grad_w = grad_output * x\n",
    "        if ctx.x_requires_grad:\n",
    "            grad_x = grad_output * w\n",
    "        else:\n",
    "            grad_x = None\n",
    "        grad_b = grad_output * 1\n",
    "        return grad_w, grad_x, grad_b, None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "分析如下：\n",
    "\n",
    "   * 自定义的Function需要继承autograd.Function，没有构造函数__init__，forward和backward函数都是静态方法\n",
    "   * backward函数的输出和forward函数的输入一一对应，backward函数的输入和forward函数的输出一一对应\n",
    "   * backward函数的grad_output参数即t.autograd.backward中的grad_variables\n",
    "   * 如果某一个输入不需要求导，直接返回None，如forward中的输入参数x_requires_grad显然无法对它求导，直接返回None即可\n",
    "   * 反向传播可能需要利用前向传播的某些中间结果，需要进行保存，否则前向传播结束后这些对象即被释放\n",
    "\n",
    "Function的使用利用Function.apply(variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.autograd import Function\n",
    "\n",
    "\n",
    "class MultiplyAdd(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, w, x, b):\n",
    "        ctx.save_for_backward(w, x)\n",
    "        output = w * x + b\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        w, x = ctx.saved_tensors\n",
    "        grad_w = grad_output * x\n",
    "        grad_x = grad_output * w\n",
    "        grad_b = grad_output * 1\n",
    "        return grad_w, grad_x, grad_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, tensor([1.]), tensor([1.]))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(1)\n",
    "w = t.rand(1, requires_grad=True)\n",
    "b = t.rand(1, requires_grad=True)\n",
    "# 开始前向传播\n",
    "z = MultiplyAdd.apply(w, x, b)\n",
    "# 开始反向传播\n",
    "z.backward()\n",
    "\n",
    "# x不需要求导，中间过程还是会计算它的导数，但随后被清空\n",
    "x.grad, w.grad, b.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([1.]), tensor([0.0996], grad_fn=<MulBackward0>), tensor([1.]))"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.ones(1)\n",
    "w = t.rand(1, requires_grad=True)\n",
    "b = t.rand(1, requires_grad=True)\n",
    "#print('开始前向传播')\n",
    "z = MultiplyAdd.apply(w, x, b)\n",
    "#print('开始反向传播')\n",
    "\n",
    "# 调用MultiplyAdd.backward\n",
    "# 输出grad_w, grad_x, grad_b\n",
    "z.grad_fn.apply(t.ones(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "之所以forward函数的输入是tensor，而backward函数的输入是variable，是为了实现高阶求导。backward函数的输入输出虽然是variable，但在实际使用时autograd.Function会将输入variable提取为tensor，并将计算结果的tensor封装成variable返回。在backward函数中，之所以也要对variable进行操作，是为了能够计算梯度的梯度（backward of backward）。下面举例说明，有关torch.autograd.grad的更详细使用请参照文档。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.], grad_fn=<MulBackward0>),)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = t.tensor([5.], requires_grad=True)\n",
    "y = x**2\n",
    "grad_x = t.autograd.grad(y, x, create_graph=True)\n",
    "grad_x  # dy/dx = 2 * x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([2.]),)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grad_grad_x = t.autograd.grad(grad_x[0], x)\n",
    "grad_grad_x  # 二阶导数 d(2x)/dx = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "这种设计虽然能让autograd具有高阶求导功能，但其也限制了Tensor的使用，因autograd中反向传播的函数只能利用当前已经有的Variable操作。这个设计是在0.2版本新加入的，为了更好的灵活性，也为了兼容旧版本的代码，PyTorch还提供了另外一种扩展autograd的方法。PyTorch提供了一个装饰器@once_differentiable，能够在backward函数中自动将输入的variable提取成tensor，把计算结果的tensor自动封装成variable。有了这个特性我们就能够很方便的使用numpy/scipy中的函数，操作不再局限于variable所支持的操作。但是这种做法正如名字中所暗示的那样只能求导一次，它打断了反向传播图，不再支持高阶求导。\n",
    "\n",
    "上面所描述的都是新式Function，还有个legacy Function，可以带有__init__方法，forward和backwad函数也不需要声明为@staticmethod，但随着版本更迭，此类Function将越来越少遇到，在此不做更多介绍。\n",
    "\n",
    "此外在实现了自己的Function之后，还可以使用gradcheck函数来检测实现是否正确。gradcheck通过数值逼近来计算梯度，可能具有一定的误差，通过控制eps的大小可以控制容忍的误差。 关于这部份的内容可以参考github上开发者们的讨论1。\n",
    "\n",
    "下面举例说明如何利用Function实现sigmoid Function。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sigmoid(Function):\n",
    "    @staticmethod\n",
    "    def forward(ctx, x):\n",
    "        output = 1 / (1 + t.exp(-x))\n",
    "        ctx.save_for_backward(output)\n",
    "        return output\n",
    "\n",
    "    @staticmethod\n",
    "    def backward(ctx, grad_output):\n",
    "        output, = ctx.saved_tensors\n",
    "        grad_x = output * (1 - output) * grad_output\n",
    "        return grad_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/qy/anaconda3/envs/pytorch/lib/python3.7/site-packages/torch/autograd/gradcheck.py:170: UserWarning: At least one of the inputs that requires gradient is not of double precision floating point. This check will likely fail if all the inputs are not of double precision floating point. \n",
      "  'At least one of the inputs that requires gradient '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 采用数值逼近方式检验计算梯度的公式对不对\n",
    "test_input = t.randn(3, 4, requires_grad=True)\n",
    "t.autograd.gradcheck(Sigmoid.apply, (test_input, ), eps=1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "135 µs ± 13.3 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "166 µs ± 22.2 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n",
      "The slowest run took 6.98 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "107 µs ± 120 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "def f_sigmoid(x):\n",
    "    y = Sigmoid.apply(x)\n",
    "    y.backward(t.ones(x.size()))\n",
    "\n",
    "\n",
    "def f_naive(x):\n",
    "    y = 1 / (1 + t.exp(-x))\n",
    "    y.backward(t.ones(x.size()))\n",
    "\n",
    "\n",
    "def f_th(x):\n",
    "    y = t.sigmoid(x)\n",
    "    y.backward(t.ones(x.size()))\n",
    "\n",
    "\n",
    "x = t.randn(100, 100, requires_grad=True)\n",
    "%timeit -n 100 f_sigmoid(x)\n",
    "%timeit -n 100 f_naive(x)\n",
    "%timeit -n 100 f_th(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "显然f_sigmoid要比单纯利用autograd加减和乘方操作实现的函数快不少，因为f_sigmoid的backward优化了反向传播的过程。另外可以看出系统实现的built-in接口(t.sigmoid)更快。\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 用Variable实现线性回归"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as t\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "from IPython import display\n",
    "import numpy as np\n",
    "device = t.device('cuda:0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 设置随机数种子，保证在不同电脑上运行时下面的输出一致\n",
    "t.manual_seed(1000)\n",
    "\n",
    "\n",
    "def get_fake_data(batch_size=8):\n",
    "    ''' 产生随机数据：y=x*2+3，加上了一些噪声'''\n",
    "    x = t.rand(batch_size, 1, device=device) * 5\n",
    "    y = x * 2 + 3 + t.randn(batch_size, 1, device=device)\n",
    "    return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f2a940627b8>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 来看看产生x-y分布是什么样的\n",
    "x, y = get_fake_data()\n",
    "plt.scatter(x.squeeze().cpu().numpy(), y.squeeze().cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.9793448448181152 2.952657461166382\n"
     ]
    }
   ],
   "source": [
    "# 随机初始化参数\n",
    "w = t.rand(1, 1, device=device, requires_grad=True)\n",
    "b = t.zeros(1, 1, device=device, requires_grad=True)\n",
    "losses = np.zeros(500)\n",
    "\n",
    "lr = 0.005\n",
    "\n",
    "for ii in range(500):\n",
    "    x, y = get_fake_data(batch_size=32)\n",
    "\n",
    "    # forward：计算loss\n",
    "    y_pred = x.mm(w) + b.expand_as(y)\n",
    "    loss = 0.5 * (y_pred - y)**2\n",
    "    loss = loss.sum()\n",
    "    losses[ii] = loss.item()\n",
    "\n",
    "    # backward：手动计算梯度\n",
    "    loss.backward()\n",
    "\n",
    "    # 更新参数\n",
    "    w.data.sub_(lr * w.grad.data)\n",
    "    b.data.sub_(lr * b.grad.data)\n",
    "\n",
    "    #梯度清零\n",
    "    w.grad.data.zero_()\n",
    "    b.grad.data.zero_()\n",
    "\n",
    "    if ii % 50 == 0:\n",
    "        display.clear_output(wait=True)\n",
    "        x = t.arange(0., 6, device=device).view(-1, 1)\n",
    "        y = x.mm(w.data) + b.data.expand_as(x)\n",
    "        plt.plot(x.cpu().numpy(), y.cpu().numpy())\n",
    "\n",
    "        x2, y2 = get_fake_data(batch_size=20)\n",
    "        plt.scatter(x2.cpu().numpy(), y2.cpu().numpy())\n",
    "\n",
    "        plt.xlim(0, 5)\n",
    "        plt.ylim(0, 13)\n",
    "        plt.show()\n",
    "        plt.pause(0.5)\n",
    "\n",
    "print(w.item(), b.item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 50)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(losses)\n",
    "plt.ylim(5, 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "用autograd实现的线性回归最大的不同点就在于autograd不需要计算反向传播，可以自动计算微分。这点不单是在深度学习，在许多机器学习的问题中都很有用。另外需要注意的是在每次反向传播之前要记得先把梯度清零。\n",
    "\n",
    "Tensor是一个类似Numpy数组的高效多维数值运算数据结构，有着和Numpy相类似的接口，并提供简单易用的GPU加速。Variable是autograd封装了Tensor并提供自动求导技术的，具有和Tensor几乎一样的接口。autograd是PyTorch的自动微分引擎，采用动态计算图技术，能够快速高效的计算导数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
